{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b4fda6",
   "metadata": {},
   "source": [
    "# Task 1 - Data Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e05ca0",
   "metadata": {},
   "source": [
    "In this task, we collect New York Times Archive data through the Archive API. This API returns the data based on the date range we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f376e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d841497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End time would be the current date, years = 1 means that we would be fetching data of 1 year.\n",
    "end = datetime.date.today()\n",
    "start = end - relativedelta(years=1)\n",
    "#Creating a list having all the dates that we require.\n",
    "months_in_range = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %-m\").tolist()]\n",
    "\n",
    "#This function is used to send a request to the API. We concatenate the base url with the date followed by the API key.\n",
    "def sendRequest(date):\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + \"kzIdsTwX2ed0OKy0ZUSiv90i0eHTn4Ud\"\n",
    "    response = requests.get(url).json() #Sending a GET request.\n",
    "    time.sleep(6)\n",
    "    return response\n",
    "\n",
    "\n",
    "def isValid(article, date):\n",
    "    is_in_range = date > start and date < end #Checking if the given date range is valid\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys() #Checking if the article has headline, if not then we wouldn't be considering that record.\n",
    "    return is_in_range and has_headline\n",
    "\n",
    "#In this function, we create a dictionary having the column names as the key and values to be an empty list.\n",
    "def parseResponse(response):\n",
    "    data = {'headline': [],  \n",
    "        'date': [],\n",
    "        'id': [],\n",
    "        'doc_type': [],\n",
    "        'material_type': [],\n",
    "        'sectionname': [],\n",
    "        'keywords': [],\n",
    "        'printpage': [],\n",
    "        'wordcount':[],\n",
    "        'newsdesk':[]}\n",
    "    \n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date() #pub_date represent the published date.\n",
    "        if is_valid(article, date): #Here we're basically appending the data from nyt to the dictionary.\n",
    "            data['date'].append(date)\n",
    "            if '_id' in article:\n",
    "                data['id'].append(article['_id'])\n",
    "            else:\n",
    "                data['id'].append(None)\n",
    "            data['headline'].append(article['headline']['main']) \n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            if 'type_of_material' in article: \n",
    "                data['material_type'].append(article['type_of_material'])\n",
    "            else:\n",
    "                data['material_type'].append(None)\n",
    "            if 'print_page' in article:\n",
    "                data['printpage'].append(article['print_page'])\n",
    "            else:\n",
    "                data['printpage'].append(None)\n",
    "            \n",
    "            data['wordcount'].append(article['word_count'])\n",
    "            data['sectionname'].append(article['section_name'])\n",
    "            data['newsdesk'].append(article['news_desk'])\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "    return pd.DataFrame(data) #finally returning the data in the form of dataframe.\n",
    "\n",
    "def getData(dates):\n",
    "    #Sends and parses request/response to/from NYT Archive API for given dates.\n",
    "    total=0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'): #Creating a direcrtory called headlines to store all the csv files based on month.\n",
    "        os.mkdir('headlines')\n",
    "    for date in dates:\n",
    "        print('Working on ' + str(date) + '...')\n",
    "        csv_path = 'headlines/' + date[0] + '-' + date[1] + '.csv' #File naming format.\n",
    "        if not os.path.exists(csv_path): # If we don't already have this month\n",
    "            response = sendRequest(date)\n",
    "            if response is not None:\n",
    "                df = parseResponse(response)\n",
    "                total += len(df)\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print('Saving ' + csv_path + '...')\n",
    "    print('Number of articles collected: ' + str(total))\n",
    "        \n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6debfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: ['2021', '12'] to ['2022', '11']\n",
      "Working on ['2021', '12']...\n",
      "Saving headlines/2021-12.csv...\n",
      "Working on ['2022', '1']...\n",
      "Saving headlines/2022-1.csv...\n",
      "Working on ['2022', '2']...\n",
      "Saving headlines/2022-2.csv...\n",
      "Working on ['2022', '3']...\n",
      "Saving headlines/2022-3.csv...\n",
      "Working on ['2022', '4']...\n",
      "Saving headlines/2022-4.csv...\n",
      "Working on ['2022', '5']...\n",
      "Saving headlines/2022-5.csv...\n",
      "Working on ['2022', '6']...\n",
      "Saving headlines/2022-6.csv...\n",
      "Working on ['2022', '7']...\n",
      "Saving headlines/2022-7.csv...\n",
      "Working on ['2022', '8']...\n",
      "Saving headlines/2022-8.csv...\n",
      "Working on ['2022', '9']...\n",
      "Saving headlines/2022-9.csv...\n",
      "Working on ['2022', '10']...\n",
      "Saving headlines/2022-10.csv...\n",
      "Working on ['2022', '11']...\n",
      "Saving headlines/2022-11.csv...\n",
      "Number of articles collected: 44673\n"
     ]
    }
   ],
   "source": [
    "getData(months_in_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2a369",
   "metadata": {},
   "source": [
    "Merging all the csv files into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fdbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"/Users/aditya/Desktop/Sem 1/Data Science/Assignment 1/headlines\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
